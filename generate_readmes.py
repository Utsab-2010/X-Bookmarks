#!/usr/bin/env python
# -*- coding: utf-8 -*-
import sys
import io
import pandas as pd
from datetime import datetime
import os
from pathlib import Path

# Force UTF-8 encoding for stdout/stderr
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
if sys.stderr.encoding != 'utf-8':
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def parse_date(date_string):
    """
    Parse Twitter date format: 'Sun Jan 04 11:01:05 +0000 2026'
    Returns formatted date and datetime object for sorting
    """
    try:
        dt = datetime.strptime(date_string.split('+')[0].strip(), '%a %b %d %H:%M:%S %Y')
        formatted = dt.strftime('%B %d, %Y')
        return formatted, dt
    except:
        return date_string, datetime.min

def sanitize_summary(text, max_length=150):
    """
    Sanitize and truncate text for summary
    """
    if not isinstance(text, str):
        return "No summary available"
    
    text = text.strip()
    # Remove extra whitespace and newlines
    text = ' '.join(text.split())
    
    if len(text) > max_length:
        text = text[:max_length].rsplit(' ', 1)[0] + '...'
    
    return text

def create_readme_for_category(df_category, category_name, output_dir='README_Categories'):
    """
    Create a README file for a specific category with table format
    """
    # Create output directory if it doesn't exist
    Path(output_dir).mkdir(exist_ok=True)
    
    # Sort by date (latest first)
    df_category['DateTime'] = df_category['Created_At'].apply(lambda x: parse_date(x)[1])
    df_sorted = df_category.sort_values('DateTime', ascending=False)
    
    # Create markdown filename from category name
    filename = category_name.lower().replace(' ', '_').replace(',', '') + '.md'
    filepath = os.path.join(output_dir, filename)
    
    # Start building the markdown content
    markdown_content = f"""# {category_name}

> A curated collection of bookmarks related to {category_name.lower()}

Last updated: {datetime.now().strftime('%B %d, %Y at %H:%M:%S')}

| # | Summary | Link | Date |
|---|---------|------|------|
"""
    
    # Add each bookmark as a row
    for idx, (_, row) in enumerate(df_sorted.iterrows(), 1):
        formatted_date, _ = parse_date(row['Created_At'])
        summary = sanitize_summary(row['Text'])
        url = row['URL']
        username = row['Username']
        
        # Create markdown row
        markdown_content += f"| {idx} | {summary} | [Link]({url}) by [@{username}](https://x.com/{username}) | {formatted_date} |\n"
    
    markdown_content += f"\n---\n\n**Total bookmarks in this category:** {len(df_sorted)}\n"
    
    # Write to file
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    print(f"‚úÖ Generated: {filepath} ({len(df_sorted)} bookmarks)")
    return filepath

def generate_main_index(output_dir='README_Categories'):
    """
    Generate a main index README that links to all categories
    """
    Path(output_dir).mkdir(exist_ok=True)
    
    # Load the organized bookmarks
    csv_file = 'organized_bookmarks_v2.csv'
    if not os.path.exists(csv_file):
        print("‚ùå organized_bookmarks_v2.csv not found!")
        return
    
    df = pd.read_csv(csv_file, encoding='utf-8')
    
    # Get unique categories
    categories = sorted(df['Category'].unique())
    
    # Create main index
    index_content = """# üìö Twitter Bookmarks - Organized Collection

> Automatically organized bookmarks from Twitter/X, segregated by topic and updated regularly.

## üìã Categories

"""
    
    total_bookmarks = len(df)
    
    for category in categories:
        count = len(df[df['Category'] == category])
        filename = category.lower().replace(' ', '_').replace(',', '') + '.md'
        index_content += f"- **[{category}]({filename})** - {count} bookmarks\n"
    
    index_content += f"""

---

**Total Bookmarks:** {total_bookmarks}  
**Last Updated:** {datetime.now().strftime('%B %d, %Y at %H:%M:%S')}

## üîÑ How It Works

1. Bookmarks are automatically scraped from Twitter/X
2. Each bookmark is categorized using ML-based zero-shot classification
3. READMEs are generated with the latest bookmarks at the top
4. This entire process runs automatically each time the script executes

## üìñ Format

Each category README contains:
- **Summary**: First 150 characters of the post
- **Link**: Direct link to the original tweet with author mention
- **Date**: Formatted publication date

---

Generated by Twitter Bookmarks Organizer
"""
    
    index_path = os.path.join(output_dir, 'README.md')
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_content)
    
    print(f"‚úÖ Generated main index: {index_path}")

def main():
    """
    Main function to generate all README files
    """
    csv_file = 'organized_bookmarks_v2.csv'
    
    if not os.path.exists(csv_file):
        print("‚ùå organized_bookmarks_v2.csv not found!")
        print("Please run the scraper and categorization first.")
        return
    
    print("üìñ Starting README generation...")
    print("=" * 50)
    
    # Load the organized bookmarks
    df = pd.read_csv(csv_file, encoding='utf-8')
    
    # Get unique categories
    categories = sorted(df['Category'].unique())
    
    print(f"Found {len(categories)} categories")
    print("=" * 50)
    
    # Generate README for each category
    for category in categories:
        df_category = df[df['Category'] == category]
        create_readme_for_category(df_category, category)
    
    print("=" * 50)
    
    # Generate main index
    generate_main_index()
    
    print("=" * 50)
    print("üéâ All READMEs generated successfully!")
    print("\nüìÅ All files are in the 'README_Categories' folder")

if __name__ == "__main__":
    main()
